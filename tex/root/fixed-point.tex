\section{Fixed-Point Method}

Lagrange\footnote{According to Euler's \emph{Algebra}, at least,
Lagrange discovered this method for finding the roots of polynomials.}
discovered, if we have a polynomial which is not constant $p(x)$, then
we can find a root $r$ of $p(x)$ by iteratively computing
$r_{n+1}=p(r_{n})-r_{n}$. It turns out, amazingly enough, this works for
any continuous function $g(x)$: we can find a fixed-point by forming the
sequence $r_{n+1}=g(r_{n})$. We summarize this method in
Algorithm~\ref{alg:root:fixed-point}, and will prove it actually works.

\begin{algorithm}\label{alg:root:fixed-point}
  \caption{Fixed-Point Method for finding roots}
  \begin{algorithmic}[1]
    \Require $g$ is a continuous function
    \Require Initial guess $r_{0}$
    \Require Some tolerance $0<\varepsilon_{\text{tol}}\ll1$
    \Require Maximum number of iterations $N_{\text{max}}\in\NN$
    \Ensure $|g(\mbox{result})-\mbox{result}|<\varepsilon_{\text{tol}}$
    or method has failed
    \Function{FixedPoint}{$g$, $r_{0}$, $\varepsilon_{\text{tol}}$, $N_{\text{max}}$}
    \State Set $i\gets 1$
    \While{$i\leq N_{\text{max}}$}
      \State Set $r \gets g(r_{0})$
      \If{$|r-r_{0}|<\varepsilon_{\text{tol}}$}
        \State\Return $r_{0}$
      \EndIf
      \State Set $i\gets i+1$
      \State Set $r_{0}\gets r$
    \EndWhile
    \State\Fail ``Method failed after $N$ iterations, $N$ = '', $N_{\text{max}}$
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\begin{lemma}[Existence of fixed-point]\label{lemma:root:fixed-point:existence}
  If $g\in C[a,b]$ and $g(x)\in[a,b]$ for each $x\in[a,b]$,
  then $g$ has at least one fixed point in $[a,b]$.
\end{lemma}
\begin{proof}
  There are three cases:

  Case 1: $g(a)=a$, then we're done.

  Case 2: $g(b)=b$, then we're done.

  Case 3: $g(a)\neq a$ and $g(b)\neq b$. Without loss of generality,
  suppose $a < g(a)$ and $g(b) < b$ (the alternative case, $a > g(a)$
  and $g(b) > b$ can be handled similarly). Let
  \begin{equation}
    h(x) = g(x)-x.
  \end{equation}
  So $h(a) > 0$ and $h(b) < 0$. Then by the intermediate value theorem,
  we have a point $p\in(a,b)$ such that $h(p)=0$.
\end{proof}


\begin{lemma}[Uniqueness of fixed-point]\label{lemma:root:fixed-point:uniqueness}
  If, in addition to the conditions from
  Lemma~\ref{lemma:root:fixed-point:existence},
  $g\in C^{1}(a,b)$, and if there exists a positive
  constant $0<k<1$ such that $|g'(x)|<k$ for each $x\in(a,b)$,
  then the fixed point in $[a,b]$ is unique.
\end{lemma}
\begin{proof}
  Assume $|g'(x)|<k$ for $x\in(a,b)$ by hypothesis.

  Let $p$ and $q$ be arbitrary fixed-points.
  Assume for contradiction $p\neq q$.
  Then consider $\xi\in(p,q)$ such that
  \begin{equation}
    \frac{g(p)-g(q)}{p-q} = g'(\xi)
  \end{equation}
  by the intermediate value theorem.
  Hence
  \begin{subequations}
    \begin{align}
      |p-q| &= |g(p)-g(q)|\\
      &= |g'(\xi)|\cdot|p-q|\\
      &\leq k|p-q| < |p-q|
    \end{align}
  \end{subequations}
  which is a contradiction.
\end{proof}

\begin{thm}[Fixed-Point]\label{thm:root:fixed-point:fixed-point-thm}
  Let $g\in C[a,b]$ be such that for each $x\in[a,b]$ we have $g(x)\in[a,b]$.
  Suppose $g'(x)$ exists on $(a,b)$ and is bounded by a constant
  $0<k<1$, i.e., $|g'(x)| < k$ for each $x\in(a,b)$.

  Then for any $p_{0}\in[a,b]$, the sequence $p_{n+1}=g(p_{n})$ for
  $n\geq0$ converges to the unique fixed-point $p\in[a,b]$.
\end{thm}
\begin{proof}
  Consider the unique fixed-point $p\in[a,b]$ of $g$ by the previous two
  Lemmas~\ref{lemma:root:fixed-point:existence} and
  \ref{lemma:root:fixed-point:uniqueness}.
  Let $\{p_{n}\}_{n\in\NN_{0}}$ be the sequence generated by $g(p_{n})=p_{n+1}$.
  We use the mean value theorem to find
  \begin{equation}
    |p-p_{n}| = |g(p)-g(p_{n-1})| = |g'(\xi_{n})|\cdot |p - p_{n-1}|.
  \end{equation}
  Then using the hypothesis that $|g'(\xi_{n})|\leq k$, we have
  \begin{equation}
    |p-p_{n}|\leq k\cdot|p-p_{n-1}|.
  \end{equation}
  We find by induction
  \begin{equation}\label{eq:root:fixed-point:bounds-on-diff}
    |p-p_{n}|\leq k\cdot|p-p_{n-1}|\leq k^{2}|p-p_{n-2}|\leq\dots\leq k^{n}|p-p_{0}|.
  \end{equation}
  Since $0<k<1$, we see $|p-p_{n}|\to 0$ as $n\to\infty$; i.e.,
  the sequence $p_{n}\to p$ converges to the unique fixed-point.
\end{proof}

\begin{cor}[Error bounds]
  Let $g(x)$ satisfy the hypotheses of Theorem~\ref{thm:root:fixed-point:fixed-point-thm}. 
  Then the error using $p_{n}$ to approximate the fixed-point $p$ of $g$
  satisfies
  \begin{subequations}
    \begin{equation}
      |p_{n}-p| \leq k^{n}\max\{p_{0}-a,b-p_{0}\}
    \end{equation}
    or
    \begin{equation}
      |p_{n}-p|\leq\frac{k^{n}}{1-k}|p_{1}-p_{0}|\quad\mbox{for all }n\geq1.
    \end{equation}
  \end{subequations}
\end{cor}
\begin{proof}
  We have Eq~\eqref{eq:root:fixed-point:bounds-on-diff}
  \begin{equation}
    |p_{n}-p|\leq k^{n}|p_{0}-p|\leq k^{n}\max\{p_{0}-a,b-p_{0}\}.
  \end{equation}
  This prove the first bound.

  For the second bound, consider
  \begin{equation}
    |p_{m}-p_{n}|\leq k^{n} |p_{1}-p_{0}| (1 + k + k^{2} + \dots + k^{m-n-1}).
  \end{equation}
  How to see this? We take
  \begin{subequations}
    \begin{align}
    |p_{m}-p_{n}| &=
    |p_{m}-p_{m-1}+p_{m-1}-p_{m-2}+\dots+p_{n+1}-p_{n}|\\
    &\leq |p_{m}-p_{m-1}|+|p_{m-1}-p_{m-2}|+\dots+|p_{n+1}-p_{n}|\\
    &\leq k^{m-1}|p_{1}-p_{0}| + k^{m-2}|p_{1}-p_{0}| + \dots + k^{n}|p_{1}-p_{0}|\\
    &\leq k^{n}|p_{1}-p_{0}|(1 + k + k^{2} + \dots + k^{m-n-1}).
    \end{align}
  \end{subequations}
  Then
  \begin{subequations}
  \begin{align}
    |p - p_{n}| &= \lim_{m\to\infty}|p_{m}-p_{n}|\\
    &\leq\lim_{m\to\infty}k^{n}|p_{1}-p_{0}|\sum^{m-n-1}_{i=0}k^{i}\\
    &\leq k^{n}|p_{1}-p_{0}|\sum^{\infty}_{i=0}k^{i}
  \end{align}
  \end{subequations}
  then using the fact we have a geometric series,
  \begin{equation*}
    |p-p_{n}|\leq \frac{k^{n}}{1-k}|p_{1}-p_{0}|.\qedhere
  \end{equation*}
\end{proof}
\begin{rmk}
  The rate of convergence is related to the bound $k$ of the derivative
  $g'(x)$. The smaller the value of $k$, the faster the convergence.
\end{rmk}